
# Zollman Models

Given my account of experimental mechanistic simulations, we can now dive deeper into Zollman's network epistemology project. I'll pay special attention to how his modeling begins from a mathematical model, uses simulation to add complexity and mimic mechanism which can be manipulated. This section will be divided into three distinct parts. I'll start by determining what Zollman seeks to achieve by modeling in *The Epistemic Benefit of Transient Diversity* [@zollmanEpistemicBenefitTransient2009], then I'll dissect the model structure and conclude by pointing forward to my extensions to his work.

## Zollman's Project

Before describing the model, it is important to understand Zollman's project and research purpose so as to have a good characterization of his intent with this model. As discussed in the previous section, the intent of the model matters as it determines which target the model is supposed to represent. The choice of target and the model's fit with the goals of the project can make or break a model. Thus, here I discuss a charitable interpretation of Zollman's intentions and use those intentions to more rigorously specify his target world.

At a high level, Zollman aims to understand how a diverse cognitive division of labor in science develops. Zollman notes that science has a striking property that different scientists work on very different problems and even those working on the same problem pursue radically different strategies. Zollman paints this diversity as counter-intuitive, citing Kuhn as saying that any "shared algorithm" for deciding what to work on would lead to a lack of disagreement and to all scientists working on the same thing [p. 332 @kuhnCollectiveBeliefScientific1977]. He also cites Philip Kitcher [@kitcherDivisionCognitiveLabor1990a] and Michael Strevens [@strevensRolePriorityRule2003a] as taking a related stance which explains diversity as resulting from reward structures, for example: one which disproportionately rewards the first discoverer.

Zollman seeks to reframe the problem as a social epistemic problem of a group of individuals trying to collectively discover which theory will be most fruitful to work on. To model this, Zollman assigns a ground-truth probability of success to any given research direction. For example, an action $A$ might have a 50% probability of panning out successfully if a researcher chooses to work on it. This probability, to Zollman, is best understood as the probability of choosing a research direction that leads to true, useful knowledge given a certain amount of research effort. For example, research into CRISPR sequences and the cas9 protein turned out to be a hugely productive research endeavor, which hints that that line of research had a higher probability of success than the average research project. Conversely, cold fusion research did not pan out, which might have been because that line of research inherently had a low probability of success given the goal of room-temperature fusion seems physically implausible now. We wouldn't expect a 100% probability of success for any endeavor as bad luck, lack of funding, and other factors can sink even the best of projects.

There are many ways to interpret this probability of success as Zollman does not offer a hard and fast interpretation in his own work. However, this conception of some degree of "hardness" of a line of research relative to reward captured in the above description is more or less sufficient for understanding the high-level division of labor as Zollman seeks to do.

Zollman first makes a case for the value of diversity by highlighting the story of peptic ulcer disease. Zollman exhibits this line of research as an example of scientists collectively choosing the wrong, lower probability of success line of research to the detriment of the field. A scientist in 1954 published a highly influential study which claimed to rule out bacteria as the cause of the disease, leading most scientists to work on theories which assumed excess acid as the cause. This incorrect assumption led to failed treatments for over 50 years until a scientist revived the bacterial theory by ingesting the bacteria, causing the disease in himself, then using antibiotics to cure himself. While this scientist did eventually right the course of that field, the anecdote begs the question: why did the field get so off course and how could that have been prevented? Zollman posits that the field jumped too quickly to monoculture and designs his model to determine which practices might encourage a healthy level of diversity.

Within this framing, Zollman seeks to see if the following rules lead to diversity in the field:

1. Limiting agents to working on a single theory at a time
2. Giving agents prior beliefs about each theory
3. Allowing agents to observe limited information from others in the community

Zollman ultimately finds that these rules do encourage diversity when information is sufficiently limited or when agents have extreme priors. Though, when both cases are true, the diversity becomes detrimental and scientists never drop inferior theories. From these results, Zollman concludes that diversity is not an inherent goal, as it can prevent convergence to a "better" theory, though it is helpful temporarily to reach an optimal result. Furthermore, Zollman emphasizes that this social model demonstrates that behavior that seems sub-optimal for an individual can become optimal within a community structure. From these modeling results, Zollman concludes that limiting information exposed to scientists or scientists holding more extreme priors creates transient diversity, which ensures theories aren't discarded too quickly so the overall community reaches more optimal results.

Given these intentions, I attribute Zollman's transient diversity model (referred to as $M_d$), as corresponding to the target world which contains real scientists acting within a real community structure ($W_s$). I argue a correspondence to the real world is a charitable interpretation as Zollman includes a real-world anecdote about real scientists and concludes by calling transient diversity a virtue for science. Furthermore, Zollman claims that the peptic ulcer disease snafu might not have been so damaging "had Palmerâ€™s result not been communicated so widely or had people been sufficiently extreme in their beliefs that many remained unconvinced by his study" [p. 33 @zollmanEpistemicBenefitTransient2009], indicating that he does take these findings as applying to actual scientists.

However, there is one important distinction to be made with the model between the actual and hypothetical worlds. A model concerning an actual world would model the world and phenomena we could, in principle observe, whereas one targeting a hypothetical world models phenomena we couldn't directly observe without making some sort of modification or intervention. Thus, he needs a manipulable model to convincingly establish an explanation through intervention. If the proposed interventions seem to cause the phenomena of interest, then they seem like plausible interventions. Having a simulation as a model is critical to this because it allows Zollman to vary aspects of it and show that phenomena appear and disappear in response.

## The Model Algorithmically

Before discussing model-target relationships, I'll first partition the model into pieces that each have their own distinct targets as described in the previous chapter. Zollman pulls the generic model structure from an earlier work by Bala and Goyal [@balaLearningNeighbours1998] which presents a model that combines graph structure and bandit problems as a means of modeling social learning. Thus, to understand Zollman's models, we first must understand Bala and Goyal's model $M_{bg}$. While such models are inherently about social structure, I'll start by describing individual behavior to emphasize how social structure affects this behavior.

In $M_{bg}$, we refer to the piece of model machinery meant to represent a person as an *individual*. Each individual is tasked with picking a way to act without knowing *a priori* the probabilities of success for each possible action. Furthermore, the individuals are arranged in a graph structure that defines the neighbors of each individual. More formally, I can define the structure of the model as follows:

$$ M_{bg} = (G, I, A) G = (V, E) I = \{ i_1, \ldots, i_{|V|} \} A = \{ a_1, \ldots, a_n \}$$

In the above, $G$ is a graph, which is composed of a set of vertices $V$ and a set of edges $E$. $I$ is a list of individuals, each corresponding to a vertex in the graph $G$. Finally, $A$ holds all the possible actions to take in the world.

Now, consider an individual $i_n$. $i_n$ corresponds to the node $n \in V$ and holds beliefs about each of the actions in $A$. An individual might hold a set of beliefs $B$ where $|B| = |A|$ and each element $b_j$ is a belief distribution about $a_j$. In Zollman, each belief is modeled as a Beta distribution that is randomly initialized with values $\alpha, \beta \in \left[0, 4\right]$:

$$b_j \sim Beta(\alpha, \beta)$$

Each action is modeled as a binomial distribution which, in turn, models some number of trials with a given probability of success (Zollman uses $n = 1000$ and $p = 0.5$ and $p = 0.499$ for the two possible actions in his models):

$$a_k \sim B\left(n = 1000, p \in \left\{0.5, 0.499 \right\}\right)$$

Each individual is composed of a set of beliefs and mechanisms for running experiments, sharing data with neighboring individuals, and updating their beliefs in response to observed data. At each step, each individual picks the highest probability belief $b_j$, draws from the corresponding action $a_j$ and receives a number of successes $s$ out of the $n = 1000$ trials. The individual then shares its results with neighbors and compiles the total number of successes $s_j$ and trials $n_j$ for each action $a_j$. Then for each action $a_j$, the individual updates its corresponding beliefs:

$$a_j = \beta(\alpha + s_j, \beta + n_j - s_j)$$

This process continues for a set number of steps. Once it is complete, each agent can be assessed by determining if its beliefs instruct it to pick the action defined to have the highest probability.

## Next Steps

Zollman's graph structures are fairly unrealistic and thus it isn't clear those structures actually represent the target, which is real scientists in real communities. While I'll go into the exact structures he used later, this section specifically seemed ripe for a more realistic modeling method due to the proliferation of detailed empirical data on scientific community structure.

There are many other parts of this model that are very simplified and which I did not re-implement with a more accurate model. Modeling people as only having two choices about what to do and limiting people to only hold a beta distribution's worth of information about both of them seems very oversimplified. Modeling researcher's opinions of an entire research direction as a single beta distribution approximating probability of success feels reductionist when all sorts of factors from interest to cultural fit play a large role in what fields researchers decide to spend years of their lives working on. However, increasing the resolution of the community structures adds realism where Zollman is most interested. Zollman is interested in what community structures lead to better science, so the community structures he discusses should be as realistic as possible. Even if he is going for a normative claim, he should be arguing for something that seems realistic and possible and the best starting point for that is current scientific structures.
