\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

Models have long been a critical part of the scientific method and thus
have been a significant focus of research within philosophy of science.
Models let scientists simplify, understand, and formalize intuitions,
ideas, and concepts that come up in the course of research. Mathematical
models of physical phenomena are essential parts of many major
developments in physics, including classical mechanics, general
relativity, quantum theory, and many others. Experimentation on model
organisms like rats and mice, despite ethical debates, has become a
critical tool behind countless biomedical advances. Atmospheric models
have led to reasonably accurate, if imperfect, weather forecasts, which
can predict the paths of hurricanes and save lives. An incorrect model
of biological neurons has led to artificial neural networks that
routinely top the scoreboard of image classification tests.

Because of the critical role that models play in science, there has been
extensive debate over their role in the scientific method and deep
questions about their epistemic status in the social sciences. At a high
level, it does seem fairly fishy that a scientist can devise a set of
rules, work out the consequences of those rules, run them as a
simulation, and then claim that process reflects the real world.
However, how do we square that with the central role they play in so
many corners of the research world? Are models merely about formalizing
assumptions we already make? Are all models wrong and only some useful?
Are some models, such as battle-tested kinematic models fundamentally
more true than models from the social sciences which often are
criticized for being too simplified and idealized to be right? If so,
how can we rectify this issue to have better models in social science?

With all these big questions in mind, this thesis turns its attention to
the role of computational and mathematical modeling in philosophy. While
philosophy does not have the same deep connections with modeling as some
fields in the natural and social sciences, modeling has played a
significant role in several different fields of philosophy ranging from
social epistemology to social contract theory. While modeling has led to
highly influential works like the evolutionary account of the social
contract \autocite{skyrmsEvolutionSocialContract2014}, big questions
remain as to how exactly simulation should be deployed and what the
epistemic status of simulation-based studies is.

While many of the epistemic concerns about philosophical models are
shared with concerns over modeling and simulation in general, the nature
of the questions philosophers seek to answer with modeling can
accentuate these issues. For example, philosophers might want to use
simulations to help make normative claims about how we should act. In
this case, the simulation or model can't simply be benchmarked against
real-world measurements in the same way a weather model might be
benchmarked against observed temperatures. If the model is supposed to
be a part of a normative claim, we might expect the result to be
different than reality if we take it that reality might simply be
imperfect.

The high-level goal of this thesis is to search for a productive framing
for simulation in philosophy that has a solid epistemic grounding, yet
allows for productive uses of simulation to help shed light on big
philosophical questions. While a sure answer to such a large question is
beyond the scope of a single work, this thesis seeks to point to a
possible productive direction and discuss what that framing might mean
for a controversial simulation-based philosophy paper.

This thesis explores the idea that the epistemic framing of
simulation-based modeling in philosophy is more similar to that of
animal-based models in biology than to mathematical models of physical
phenomena. Through this lens, we see models as imperfectly replicating
the actual mechanisms of interest in the real world in a manner that
allows for a high degree of manipulation. The simulation becomes our lab
rat that, when designed carefully, can allow a researcher to manipulate
the model in ways that would otherwise be impractical or impossible on
the actual mechanisms. Because simulations are malleable and facilitate
manipulation, they can be an ideal starting point for exploratory and
experimental research as both of these modes are enabled by
manipulation.

This framing brings up interesting questions about how these simulated
models might differ from physical models. It seems these experiments
rest on the fact that nature and evolution set the structure and
mechanism of the model. So then how could a simulation defined by a
researcher ever be an acceptable proxy for the real world? I'll argue
(and attempt to demonstrate) that by using detailed datasets about the
world, researchers can create quite convincing proxies for real-world
mechanisms by using empirical data to define model mechanism.
Essentially, by defining part of a simulation with real measurements
rather than theoretical models, that simulation can more plausibly mimic
its target allowing the simulation to act more as a lab rat than a
thought experiment.

More concretely, this thesis will begin with a discussion of models that
provides background on the salient issues about models in science, then
draws from mechanist and manipulationist accounts of science to motivate
my view of simulations as tools for exploration and experimentation.

Next, I will introduce Kevin Zollman's ``network epistemology'' project
which uses simulation to study the social epistemology of science
\autocite{zollmanNetworkEpistemologyCommunication2013,zollmanEpistemicBenefitTransient2009}.
I'll frame some of the existing issues critics have flagged with the
simulations, most critically the parameter-sensitivity of the models
\autocite{rosenstockEpistemicNetworksLess2017a}. However, I'll argue
that this project can be framed better as experiments performed on a
simulation model of social interactions.

Finally, I'll take my framing of Zollman's model from \emph{The
Epistemic Benefit of Transient Diversity} and rework it to much more
convincingly represent social interactions by using a comprehensive
dataset of academic publishing and citation. The goal of this section is
to demonstrate that large datasets, when used to define model mechanism
structure, can produce more convincing baseline models. Essentially,
using lots of empirical data can provide a better lab rat than more
traditional graph structures could. This modification points to how a
more experimentally-oriented simulation project might have a clearer
epistemic structure in terms of my discussion of models. This reworking
required a significant engineering component in determining an efficient
way of generating convincing graph structure from a very large citation
dataset and ensuring the model itself could run efficiently on these
much larger graphs.

In sum, this thesis is about pointing toward a more sound and convincing
foundation for simulation-based modeling. I propose using empirical data
as a means of getting there and carry out an experiment to demonstrate
how this might work out in practice. While reworking a single study
using this view is inadequate to show thoroughly that this experimental
view is the best lens to view computational modeling, it should
hopefully demonstrate that there is untapped potential here. Modeling
could be a very effective tool to help sharpen intuitions and try out
ideas, so this thesis aims to show how modeling can be another tool in
the philosopher's research toolbox.
