\hypertarget{conclusion}{%
\chapter{Conclusion}\label{conclusion}}

To conclude this thesis, I'll spend a bit of time ruminating on how
these empirical methods were useful and how they could be applied
elsewhere. To do this, I'll talk a bit about how they differ from the
robustness analysis that already done in computational modeling. To do
this, I'll paint a picture that explains when each of these tools should
be used and why. Both of these tools are designed to show that a
simulation result is robust and applies to the real world, though they
do it in very different ways.

First, I'll introduce the strategy employed by Rosenstock, Bruner, and
O'Connor \autocite{rosenstockEpistemicNetworksLess2017a}. They performed
a robustness analysis over many of the non-graph parts of the model and
found that for many choices, Zollman's results don't hold up. They
conclude that because the parameter space is large and only a very small
part of it results in Zollman's observed effect that the effect is
unlikely to occur in the real world. Overall, robustness analysis is a
very useful strategy to understand the limitations of a given model
because it helps to show in much more detail what interplay there is
between parameters. It also has the potential to identify very robust
effects that would be much more likely to apply in the real world. If
the effect holds for all parameter values, then it seems fairly likely
that the real world parameter values fall into that range! On the other
hand, as in the Zollman case, if the parameters need to be fine-tunned
to observe the effect, we'd need the parameters for the world to also be
fine-tunned in the same way for the model to apply to the real world.
Concretely, the O'Connor work most usefully identifies that the
probabilities of each action must be \emph{very} close together to get
any sort of trade-off at all. If they are even slightly further apart,
the model converges at a high rate no matter the priors or the
structure. Thus, if all the choices of action have very similar chances
of success, then the effects observed in this thesis likely still hold.
If they are further apart, more work would need to be done to see if
this sensitivity persists on the large social graphs.

Empirically-backed models try to show that a model generalizes in a very
different way. Where robustness analysis asks does this hold for all
parameters, empirical work asks does this hold for a few very
representative parameter values. The reality is that the world often
isn't robust to parameter changes so robustness analysis alone cannot
account for all phenomena in the world. For example, there are many
physical constants in the universe that, if perturbed slightly, would
make life as we know it unimaginable. There has been much debate over
what this means and the implications of it, recently over things like
the Anthropic principle or intelligent design in cosmology. However,
that doesn't change the fact that lack of robustness is a striking
feature of the world we live in.

Thus, empirical methods allow us to learn how well a model applies to
the real world by simply using real-world parameter values. This
requires data collection work analysis and understanding that isn't
present for all aspects of the world, however, for many we do know the
parameters pretty well. For example, an engineering simulation of a
bridge on earth need not be robust to changes in the Earth's gravity
because we know that parameter to be fixed to a certain value
(\(10 m/s^2\)).

My work here does a similar thing for social networks. Because of the
extensive empirical work cataloging citations, we now have a very
comprehensive proxy which captures one important dimension of scientific
community structure. This citation structure is fairly fixed and stable
in the sense that people can only keep up with and cite the work of a
certain number of others and some people will always turn out to be more
influential than others due to media coverage, social media, etc. Thus,
models which deal with this structure only need to be robust to
variations that could feasibly occur. So a robustness analysis that
shows the model doesn't hold for cycles doesn't tell us much because
people never organize themselves in cycles except to play the game
``telephone''.

The Rosenstock, Bruner, O'Connor piece, however, does focus on
parameters that are unique to the model and not present in the real
world. This means we necessarily don't have good priors on them in the
same way we do for social network structure. Thus, a robustness analysis
is all that is possible. We don't know at all how far apart action
probabilities are in the real world because it is unclear what those
action probabilities map to in the first place. We don't know what a
reasonable initial beta distribution for belief about those actions is
either because we don't know exactly how people form prior beliefs about
the lines of work they go into. Thus, in these cases, robustness
analysis has to fill the gaps. However, ideally, we would like to
understand and observe the mechanisms at play in the real world so we
can better calibrate our models.

At the end of the day, the parameter space that matters is the one for
the real world in which we live, which is much smaller than the set of
mathematically possible parameters in many cases. Pushing for narrowing
the parameter space to what exists in the real world often elucidates
interesting results because that smaller parameter spaces can be more
thoroughly explored. My work here showed that the real world parameter
space had quite different properties than the more generalized and
idealized parameter space which Zollman tried to use in exploring the
parameter space of graph structure.

Thus, in addition to my results extending Zollman's model, this work
shows that empirical analysis within computational philosophy can be a
critical tool in addition to robustness analysis. While not possible for
every aspect modeled, finding empirical priors contextualized the model
results to a parameter space that, by definition, reflects some part of
reality. Sometimes, and as was the case with Zollman, this smaller
parameter space can shine some light on the peculiarities of our world.
For example, the fact that more communication can lead to less overall
density when an isolated community engages with the mainstream.
Philosophers would be privy to define their theories in terms of good
empirical priors wherever possible to sharpen their arguments and to
ensure that those arguments actually go through for the complicated and
rich world in which we live in.
